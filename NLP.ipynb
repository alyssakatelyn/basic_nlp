{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package omw to /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/alyssa/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stopwords', 'cmudict.zip', 'words', 'names', 'wordnet_ic.zip', 'cmudict', 'treebank.zip', 'inaugural', 'genesis.zip', 'gazetteers.zip', 'wordnet.zip', 'inaugural.zip', 'stopwords.zip', 'gutenberg', 'shakespeare.zip', 'words.zip', 'omw', 'shakespeare', 'movie_reviews', 'omw.zip', 'wordnet_ic', 'names.zip', 'wordnet', 'gutenberg.zip', 'twitter_samples.zip', 'treebank', 'genesis', 'gazetteers', 'twitter_samples', 'movie_reviews.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find('corpora')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abagael',\n",
       " 'Abagail',\n",
       " 'Abbe',\n",
       " 'Abbey',\n",
       " 'Abbi',\n",
       " 'Abbie',\n",
       " 'Abby',\n",
       " 'Abigael',\n",
       " 'Abigail',\n",
       " 'Abigale',\n",
       " 'Abra',\n",
       " 'Acacia',\n",
       " 'Ada',\n",
       " 'Adah',\n",
       " 'Adaline',\n",
       " 'Adara',\n",
       " 'Addie',\n",
       " 'Addis',\n",
       " 'Adel',\n",
       " 'Adela',\n",
       " 'Adelaide',\n",
       " 'Adele',\n",
       " 'Adelice',\n",
       " 'Adelina',\n",
       " 'Adelind',\n",
       " 'Adeline',\n",
       " 'Adella',\n",
       " 'Adelle',\n",
       " 'Adena',\n",
       " 'Adey',\n",
       " 'Adi',\n",
       " 'Adiana',\n",
       " 'Adina',\n",
       " 'Adora',\n",
       " 'Adore',\n",
       " 'Adoree',\n",
       " 'Adorne',\n",
       " 'Adrea',\n",
       " 'Adria',\n",
       " 'Adriaens',\n",
       " 'Adrian',\n",
       " 'Adriana',\n",
       " 'Adriane',\n",
       " 'Adrianna',\n",
       " 'Adrianne',\n",
       " 'Adrien',\n",
       " 'Adriena',\n",
       " 'Adrienne',\n",
       " 'Aeriel',\n",
       " 'Aeriela',\n",
       " 'Aeriell',\n",
       " 'Ag',\n",
       " 'Agace',\n",
       " 'Agata',\n",
       " 'Agatha',\n",
       " 'Agathe',\n",
       " 'Aggi',\n",
       " 'Aggie',\n",
       " 'Aggy',\n",
       " 'Agna',\n",
       " 'Agnella',\n",
       " 'Agnes',\n",
       " 'Agnese',\n",
       " 'Agnesse',\n",
       " 'Agneta',\n",
       " 'Agnola',\n",
       " 'Agretha',\n",
       " 'Aida',\n",
       " 'Aidan',\n",
       " 'Aigneis',\n",
       " 'Aila',\n",
       " 'Aile',\n",
       " 'Ailee',\n",
       " 'Aileen',\n",
       " 'Ailene',\n",
       " 'Ailey',\n",
       " 'Aili',\n",
       " 'Ailina',\n",
       " 'Ailyn',\n",
       " 'Aime',\n",
       " 'Aimee',\n",
       " 'Aimil',\n",
       " 'Aina',\n",
       " 'Aindrea',\n",
       " 'Ainslee',\n",
       " 'Ainsley',\n",
       " 'Ainslie',\n",
       " 'Ajay',\n",
       " 'Alaine',\n",
       " 'Alameda',\n",
       " 'Alana',\n",
       " 'Alanah',\n",
       " 'Alane',\n",
       " 'Alanna',\n",
       " 'Alayne',\n",
       " 'Alberta',\n",
       " 'Albertina',\n",
       " 'Albertine',\n",
       " 'Albina',\n",
       " 'Alecia',\n",
       " 'Aleda',\n",
       " 'Aleece',\n",
       " 'Aleecia',\n",
       " 'Aleen',\n",
       " 'Alejandra',\n",
       " 'Alejandrina',\n",
       " 'Alena',\n",
       " 'Alene',\n",
       " 'Alessandra',\n",
       " 'Aleta',\n",
       " 'Alethea',\n",
       " 'Alex',\n",
       " 'Alexa',\n",
       " 'Alexandra',\n",
       " 'Alexandrina',\n",
       " 'Alexi',\n",
       " 'Alexia',\n",
       " 'Alexina',\n",
       " 'Alexine',\n",
       " 'Alexis',\n",
       " 'Alfie',\n",
       " 'Alfreda',\n",
       " 'Ali',\n",
       " 'Alia',\n",
       " 'Alica',\n",
       " 'Alice',\n",
       " 'Alicea',\n",
       " 'Alicia',\n",
       " 'Alida',\n",
       " 'Alidia',\n",
       " 'Alina',\n",
       " 'Aline',\n",
       " 'Alis',\n",
       " 'Alisa',\n",
       " 'Alisha',\n",
       " 'Alison',\n",
       " 'Alissa',\n",
       " 'Alisun',\n",
       " 'Alix',\n",
       " 'Aliza',\n",
       " 'Alla',\n",
       " 'Alleen',\n",
       " 'Allegra',\n",
       " 'Allene',\n",
       " 'Alli',\n",
       " 'Allianora',\n",
       " 'Allie',\n",
       " 'Allina',\n",
       " 'Allis',\n",
       " 'Allison',\n",
       " 'Allissa',\n",
       " 'Allsun',\n",
       " 'Ally',\n",
       " 'Allyce',\n",
       " 'Allyn',\n",
       " 'Allys',\n",
       " 'Allyson',\n",
       " 'Alma',\n",
       " 'Almeda',\n",
       " 'Almeria',\n",
       " 'Almeta',\n",
       " 'Almira',\n",
       " 'Almire',\n",
       " 'Aloise',\n",
       " 'Aloisia',\n",
       " 'Aloysia',\n",
       " 'Alpa',\n",
       " 'Alta',\n",
       " 'Althea',\n",
       " 'Alvera',\n",
       " 'Alvina',\n",
       " 'Alvinia',\n",
       " 'Alvira',\n",
       " 'Alyce',\n",
       " 'Alyda',\n",
       " 'Alys',\n",
       " 'Alysa',\n",
       " 'Alyse',\n",
       " 'Alysia',\n",
       " 'Alyson',\n",
       " 'Alyss',\n",
       " 'Alyssa',\n",
       " 'Amabel',\n",
       " 'Amabelle',\n",
       " 'Amalea',\n",
       " 'Amalee',\n",
       " 'Amaleta',\n",
       " 'Amalia',\n",
       " 'Amalie',\n",
       " 'Amalita',\n",
       " 'Amalle',\n",
       " 'Amanda',\n",
       " 'Amandi',\n",
       " 'Amandie',\n",
       " 'Amandy',\n",
       " 'Amara',\n",
       " 'Amargo',\n",
       " 'Amata',\n",
       " 'Amber',\n",
       " 'Amberly',\n",
       " 'Ambrosia',\n",
       " 'Ambur',\n",
       " 'Ame',\n",
       " 'Amelia',\n",
       " 'Amelie',\n",
       " 'Amelina',\n",
       " 'Ameline',\n",
       " 'Amelita',\n",
       " 'Ami',\n",
       " 'Amie',\n",
       " 'Amity',\n",
       " 'Ammamaria',\n",
       " 'Amy',\n",
       " 'Ana',\n",
       " 'Anabel',\n",
       " 'Anabella',\n",
       " 'Anabelle',\n",
       " 'Anais',\n",
       " 'Analiese',\n",
       " 'Analise',\n",
       " 'Anallese',\n",
       " 'Anallise',\n",
       " 'Anastasia',\n",
       " 'Anastasie',\n",
       " 'Anastassia',\n",
       " 'Anatola',\n",
       " 'Andee',\n",
       " 'Andi',\n",
       " 'Andie',\n",
       " 'Andra',\n",
       " 'Andrea',\n",
       " 'Andreana',\n",
       " 'Andree',\n",
       " 'Andrei',\n",
       " 'Andria',\n",
       " 'Andriana',\n",
       " 'Andriette',\n",
       " 'Andromache',\n",
       " 'Andromeda',\n",
       " 'Andy',\n",
       " 'Anestassia',\n",
       " 'Anet',\n",
       " 'Anett',\n",
       " 'Anetta',\n",
       " 'Anette',\n",
       " 'Ange',\n",
       " 'Angel',\n",
       " 'Angela',\n",
       " 'Angele',\n",
       " 'Angelia',\n",
       " 'Angelica',\n",
       " 'Angelika',\n",
       " 'Angelina',\n",
       " 'Angeline',\n",
       " 'Angelique',\n",
       " 'Angelita',\n",
       " 'Angelle',\n",
       " 'Angie',\n",
       " 'Angil',\n",
       " 'Angy',\n",
       " 'Ania',\n",
       " 'Anica',\n",
       " 'Anissa',\n",
       " 'Anita',\n",
       " 'Anitra',\n",
       " 'Anja',\n",
       " 'Anjanette',\n",
       " 'Anjela',\n",
       " 'Ann',\n",
       " 'Ann-Mari',\n",
       " 'Ann-Marie',\n",
       " 'Anna',\n",
       " 'Anna-Diana',\n",
       " 'Anna-Diane',\n",
       " 'Anna-Maria',\n",
       " 'Annabal',\n",
       " 'Annabel',\n",
       " 'Annabela',\n",
       " 'Annabell',\n",
       " 'Annabella',\n",
       " 'Annabelle',\n",
       " 'Annadiana',\n",
       " 'Annadiane',\n",
       " 'Annalee',\n",
       " 'Annalena',\n",
       " 'Annaliese',\n",
       " 'Annalisa',\n",
       " 'Annalise',\n",
       " 'Annalyse',\n",
       " 'Annamari',\n",
       " 'Annamaria',\n",
       " 'Annamarie',\n",
       " 'Anne',\n",
       " 'Anne-Corinne',\n",
       " 'Anne-Mar',\n",
       " 'Anne-Marie',\n",
       " 'Annecorinne',\n",
       " 'Anneliese',\n",
       " 'Annelise',\n",
       " 'Annemarie',\n",
       " 'Annetta',\n",
       " 'Annette',\n",
       " 'Anni',\n",
       " 'Annice',\n",
       " 'Annie',\n",
       " 'Annissa',\n",
       " 'Annmaria',\n",
       " 'Annmarie',\n",
       " 'Annnora',\n",
       " 'Annora',\n",
       " 'Anny',\n",
       " 'Anselma',\n",
       " 'Ansley',\n",
       " 'Anstice',\n",
       " 'Anthe',\n",
       " 'Anthea',\n",
       " 'Anthia',\n",
       " 'Antoinette',\n",
       " 'Antonella',\n",
       " 'Antonetta',\n",
       " 'Antonia',\n",
       " 'Antonie',\n",
       " 'Antonietta',\n",
       " 'Antonina',\n",
       " 'Anya',\n",
       " 'Aphrodite',\n",
       " 'Appolonia',\n",
       " 'April',\n",
       " 'Aprilette',\n",
       " 'Ara',\n",
       " 'Arabel',\n",
       " 'Arabela',\n",
       " 'Arabele',\n",
       " 'Arabella',\n",
       " 'Arabelle',\n",
       " 'Arda',\n",
       " 'Ardath',\n",
       " 'Ardeen',\n",
       " 'Ardelia',\n",
       " 'Ardelis',\n",
       " 'Ardella',\n",
       " 'Ardelle',\n",
       " 'Arden',\n",
       " 'Ardene',\n",
       " 'Ardenia',\n",
       " 'Ardine',\n",
       " 'Ardis',\n",
       " 'Ardith',\n",
       " 'Ardra',\n",
       " 'Ardyce',\n",
       " 'Ardys',\n",
       " 'Ardyth',\n",
       " 'Aretha',\n",
       " 'Ariadne',\n",
       " 'Ariana',\n",
       " 'Arianne',\n",
       " 'Aridatha',\n",
       " 'Ariel',\n",
       " 'Ariela',\n",
       " 'Ariella',\n",
       " 'Arielle',\n",
       " 'Arlana',\n",
       " 'Arlee',\n",
       " 'Arleen',\n",
       " 'Arlen',\n",
       " 'Arlena',\n",
       " 'Arlene',\n",
       " 'Arleta',\n",
       " 'Arlette',\n",
       " 'Arleyne',\n",
       " 'Arlie',\n",
       " 'Arliene',\n",
       " 'Arlina',\n",
       " 'Arlinda',\n",
       " 'Arline',\n",
       " 'Arly',\n",
       " 'Arlyn',\n",
       " 'Arlyne',\n",
       " 'Aryn',\n",
       " 'Ashely',\n",
       " 'Ashlee',\n",
       " 'Ashleigh',\n",
       " 'Ashlen',\n",
       " 'Ashley',\n",
       " 'Ashli',\n",
       " 'Ashlie',\n",
       " 'Ashly',\n",
       " 'Asia',\n",
       " 'Astra',\n",
       " 'Astrid',\n",
       " 'Astrix',\n",
       " 'Atalanta',\n",
       " 'Athena',\n",
       " 'Athene',\n",
       " 'Atlanta',\n",
       " 'Atlante',\n",
       " 'Auberta',\n",
       " 'Aubine',\n",
       " 'Aubree',\n",
       " 'Aubrette',\n",
       " 'Aubrey',\n",
       " 'Aubrie',\n",
       " 'Aubry',\n",
       " 'Audi',\n",
       " 'Audie',\n",
       " 'Audra',\n",
       " 'Audre',\n",
       " 'Audrey',\n",
       " 'Audrie',\n",
       " 'Audry',\n",
       " 'Audrye',\n",
       " 'Audy',\n",
       " 'Augusta',\n",
       " 'Auguste',\n",
       " 'Augustina',\n",
       " 'Augustine',\n",
       " 'Aura',\n",
       " 'Aurea',\n",
       " 'Aurel',\n",
       " 'Aurelea',\n",
       " 'Aurelia',\n",
       " 'Aurelie',\n",
       " 'Auria',\n",
       " 'Aurie',\n",
       " 'Aurilia',\n",
       " 'Aurlie',\n",
       " 'Auroora',\n",
       " 'Aurora',\n",
       " 'Aurore',\n",
       " 'Austin',\n",
       " 'Austina',\n",
       " 'Austine',\n",
       " 'Ava',\n",
       " 'Aveline',\n",
       " 'Averil',\n",
       " 'Averyl',\n",
       " 'Avie',\n",
       " 'Avis',\n",
       " 'Aviva',\n",
       " 'Avivah',\n",
       " 'Avril',\n",
       " 'Avrit',\n",
       " 'Ayn',\n",
       " 'Bab',\n",
       " 'Babara',\n",
       " 'Babette',\n",
       " 'Babita',\n",
       " 'Babs',\n",
       " 'Bambi',\n",
       " 'Bambie',\n",
       " 'Bamby',\n",
       " 'Barb',\n",
       " 'Barbabra',\n",
       " 'Barbara',\n",
       " 'Barbara-Anne',\n",
       " 'Barbaraanne',\n",
       " 'Barbe',\n",
       " 'Barbee',\n",
       " 'Barbette',\n",
       " 'Barbey',\n",
       " 'Barbi',\n",
       " 'Barbie',\n",
       " 'Barbra',\n",
       " 'Barby',\n",
       " 'Bari',\n",
       " 'Barrie',\n",
       " 'Barry',\n",
       " 'Basia',\n",
       " 'Bathsheba',\n",
       " 'Batsheva',\n",
       " 'Bea',\n",
       " 'Beatrice',\n",
       " 'Beatrisa',\n",
       " 'Beatrix',\n",
       " 'Beatriz',\n",
       " 'Beau',\n",
       " 'Bebe',\n",
       " 'Becca',\n",
       " 'Becka',\n",
       " 'Becki',\n",
       " 'Beckie',\n",
       " 'Becky',\n",
       " 'Bee',\n",
       " 'Beilul',\n",
       " 'Beitris',\n",
       " 'Bekki',\n",
       " 'Bel',\n",
       " 'Belia',\n",
       " 'Belicia',\n",
       " 'Belinda',\n",
       " 'Belita',\n",
       " 'Bell',\n",
       " 'Bella',\n",
       " 'Bellamy',\n",
       " 'Bellanca',\n",
       " 'Belle',\n",
       " 'Bellina',\n",
       " 'Belva',\n",
       " 'Belvia',\n",
       " 'Bendite',\n",
       " 'Benedetta',\n",
       " 'Benedicta',\n",
       " 'Benedikta',\n",
       " 'Benetta',\n",
       " 'Benita',\n",
       " 'Benni',\n",
       " 'Bennie',\n",
       " 'Benny',\n",
       " 'Benoite',\n",
       " 'Berenice',\n",
       " 'Beret',\n",
       " 'Berget',\n",
       " 'Berna',\n",
       " 'Bernadene',\n",
       " 'Bernadette',\n",
       " 'Bernadina',\n",
       " 'Bernadine',\n",
       " 'Bernardina',\n",
       " 'Bernardine',\n",
       " 'Bernelle',\n",
       " 'Bernete',\n",
       " 'Bernetta',\n",
       " 'Bernette',\n",
       " 'Berni',\n",
       " 'Bernice',\n",
       " 'Bernie',\n",
       " 'Bernita',\n",
       " 'Berny',\n",
       " 'Berri',\n",
       " 'Berrie',\n",
       " 'Berry',\n",
       " 'Bert',\n",
       " 'Berta',\n",
       " 'Berte',\n",
       " 'Bertha',\n",
       " 'Berthe',\n",
       " 'Berti',\n",
       " 'Bertie',\n",
       " 'Bertina',\n",
       " 'Bertine',\n",
       " 'Berty',\n",
       " 'Beryl',\n",
       " 'Beryle',\n",
       " 'Bess',\n",
       " 'Bessie',\n",
       " 'Bessy',\n",
       " 'Beth',\n",
       " 'Bethanne',\n",
       " 'Bethany',\n",
       " 'Bethena',\n",
       " 'Bethina',\n",
       " 'Betsey',\n",
       " 'Betsy',\n",
       " 'Betta',\n",
       " 'Bette',\n",
       " 'Bette-Ann',\n",
       " 'Betteann',\n",
       " 'Betteanne',\n",
       " 'Betti',\n",
       " 'Bettie',\n",
       " 'Bettina',\n",
       " 'Bettine',\n",
       " 'Betty',\n",
       " 'Bettye',\n",
       " 'Beulah',\n",
       " 'Bev',\n",
       " 'Beverie',\n",
       " 'Beverlee',\n",
       " 'Beverlie',\n",
       " 'Beverly',\n",
       " 'Bevvy',\n",
       " 'Bianca',\n",
       " 'Bianka',\n",
       " 'Biddy',\n",
       " 'Bidget',\n",
       " 'Bill',\n",
       " 'Billi',\n",
       " 'Billie',\n",
       " 'Billy',\n",
       " 'Binni',\n",
       " 'Binnie',\n",
       " 'Binny',\n",
       " 'Bird',\n",
       " 'Birdie',\n",
       " 'Birgit',\n",
       " 'Birgitta',\n",
       " 'Blair',\n",
       " 'Blaire',\n",
       " 'Blake',\n",
       " 'Blakelee',\n",
       " 'Blakeley',\n",
       " 'Blanca',\n",
       " 'Blanch',\n",
       " 'Blancha',\n",
       " 'Blanche',\n",
       " 'Blinni',\n",
       " 'Blinnie',\n",
       " 'Blinny',\n",
       " 'Bliss',\n",
       " 'Blisse',\n",
       " 'Blithe',\n",
       " 'Blondell',\n",
       " 'Blondelle',\n",
       " 'Blondie',\n",
       " 'Blondy',\n",
       " 'Blythe',\n",
       " 'Bo',\n",
       " 'Bobbette',\n",
       " 'Bobbi',\n",
       " 'Bobbie',\n",
       " 'Bobby',\n",
       " 'Bobette',\n",
       " 'Bobina',\n",
       " 'Bobine',\n",
       " 'Bobinette',\n",
       " 'Bonita',\n",
       " 'Bonnee',\n",
       " 'Bonni',\n",
       " 'Bonnie',\n",
       " 'Bonny',\n",
       " 'Brana',\n",
       " 'Brandais',\n",
       " 'Brande',\n",
       " 'Brandea',\n",
       " 'Brandi',\n",
       " 'Brandice',\n",
       " 'Brandie',\n",
       " 'Brandise',\n",
       " 'Brandy',\n",
       " 'Brea',\n",
       " 'Breanne',\n",
       " 'Brear',\n",
       " 'Bree',\n",
       " 'Breena',\n",
       " 'Bren',\n",
       " 'Brena',\n",
       " 'Brenda',\n",
       " 'Brenn',\n",
       " 'Brenna',\n",
       " 'Brett',\n",
       " 'Bria',\n",
       " 'Briana',\n",
       " 'Brianna',\n",
       " 'Brianne',\n",
       " 'Bride',\n",
       " 'Bridget',\n",
       " 'Bridgett',\n",
       " 'Bridgette',\n",
       " 'Bridie',\n",
       " 'Brier',\n",
       " 'Brietta',\n",
       " 'Brigid',\n",
       " 'Brigida',\n",
       " 'Brigit',\n",
       " 'Brigitta',\n",
       " 'Brigitte',\n",
       " 'Brina',\n",
       " 'Briney',\n",
       " 'Briny',\n",
       " 'Brit',\n",
       " 'Brita',\n",
       " 'Britaney',\n",
       " 'Britani',\n",
       " 'Briteny',\n",
       " 'Britney',\n",
       " 'Britni',\n",
       " 'Britt',\n",
       " 'Britta',\n",
       " 'Brittan',\n",
       " 'Brittany',\n",
       " 'Britte',\n",
       " 'Brittney',\n",
       " 'Brook',\n",
       " 'Brooke',\n",
       " 'Brooks',\n",
       " 'Brunella',\n",
       " 'Brunhilda',\n",
       " 'Brunhilde',\n",
       " 'Bryana',\n",
       " 'Bryn',\n",
       " 'Bryna',\n",
       " 'Brynn',\n",
       " 'Brynna',\n",
       " 'Brynne',\n",
       " 'Buffy',\n",
       " 'Bunni',\n",
       " 'Bunnie',\n",
       " 'Bunny',\n",
       " 'Burta',\n",
       " 'Cabrina',\n",
       " 'Cacilia',\n",
       " 'Cacilie',\n",
       " 'Caitlin',\n",
       " 'Caitrin',\n",
       " 'Cal',\n",
       " 'Calida',\n",
       " 'Calla',\n",
       " 'Calley',\n",
       " 'Calli',\n",
       " 'Callida',\n",
       " 'Callie',\n",
       " 'Cally',\n",
       " 'Calypso',\n",
       " 'Cam',\n",
       " 'Camala',\n",
       " 'Camel',\n",
       " 'Camella',\n",
       " 'Camellia',\n",
       " 'Cameo',\n",
       " 'Cami',\n",
       " 'Camila',\n",
       " 'Camile',\n",
       " 'Camilla',\n",
       " 'Camille',\n",
       " 'Cammi',\n",
       " 'Cammie',\n",
       " 'Cammy',\n",
       " 'Canada',\n",
       " 'Candace',\n",
       " 'Candi',\n",
       " 'Candice',\n",
       " 'Candida',\n",
       " 'Candide',\n",
       " 'Candie',\n",
       " 'Candis',\n",
       " 'Candra',\n",
       " 'Candy',\n",
       " 'Cappella',\n",
       " 'Caprice',\n",
       " 'Cara',\n",
       " 'Caralie',\n",
       " 'Caren',\n",
       " 'Carena',\n",
       " 'Caresa',\n",
       " 'Caressa',\n",
       " 'Caresse',\n",
       " 'Carey',\n",
       " 'Cari',\n",
       " 'Caria',\n",
       " 'Carie',\n",
       " 'Caril',\n",
       " 'Carilyn',\n",
       " 'Carin',\n",
       " 'Carina',\n",
       " 'Carine',\n",
       " 'Cariotta',\n",
       " 'Carissa',\n",
       " 'Carita',\n",
       " 'Caritta',\n",
       " 'Carla',\n",
       " 'Carlee',\n",
       " 'Carleen',\n",
       " 'Carlen',\n",
       " 'Carlena',\n",
       " 'Carlene',\n",
       " 'Carley',\n",
       " 'Carli',\n",
       " 'Carlie',\n",
       " 'Carlin',\n",
       " 'Carlina',\n",
       " 'Carline',\n",
       " 'Carlisle',\n",
       " 'Carlita',\n",
       " 'Carlota',\n",
       " 'Carlotta',\n",
       " 'Carly',\n",
       " 'Carlye',\n",
       " 'Carlyn',\n",
       " 'Carlynn',\n",
       " 'Carlynne',\n",
       " 'Carma',\n",
       " 'Carmel',\n",
       " 'Carmela',\n",
       " 'Carmelia',\n",
       " 'Carmelina',\n",
       " 'Carmelita',\n",
       " 'Carmella',\n",
       " 'Carmelle',\n",
       " 'Carmen',\n",
       " 'Carmina',\n",
       " 'Carmine',\n",
       " 'Carmita',\n",
       " 'Carmon',\n",
       " 'Caro',\n",
       " 'Carol',\n",
       " 'Carol-Jean',\n",
       " 'Carola',\n",
       " 'Carolan',\n",
       " 'Carolann',\n",
       " 'Carole',\n",
       " 'Carolee',\n",
       " 'Caroleen',\n",
       " 'Carolie',\n",
       " 'Carolin',\n",
       " 'Carolina',\n",
       " 'Caroline',\n",
       " 'Caroljean',\n",
       " 'Carolyn',\n",
       " 'Carolyne',\n",
       " 'Carolynn',\n",
       " 'Caron',\n",
       " 'Carree',\n",
       " 'Carri',\n",
       " 'Carrie',\n",
       " 'Carrissa',\n",
       " 'Carrol',\n",
       " 'Carroll',\n",
       " 'Carry',\n",
       " 'Cary',\n",
       " 'Caryl',\n",
       " 'Caryn',\n",
       " 'Casandra',\n",
       " 'Casey',\n",
       " 'Casi',\n",
       " 'Casia',\n",
       " 'Casie',\n",
       " 'Cass',\n",
       " 'Cassandra',\n",
       " 'Cassandre',\n",
       " 'Cassandry',\n",
       " 'Cassaundra',\n",
       " 'Cassey',\n",
       " 'Cassi',\n",
       " 'Cassie',\n",
       " 'Cassondra',\n",
       " 'Cassy',\n",
       " 'Cat',\n",
       " 'Catarina',\n",
       " 'Cate',\n",
       " 'Caterina',\n",
       " 'Catha',\n",
       " 'Catharina',\n",
       " 'Catharine',\n",
       " 'Cathe',\n",
       " 'Cathee',\n",
       " 'Catherin',\n",
       " 'Catherina',\n",
       " 'Catherine',\n",
       " 'Cathi',\n",
       " 'Cathie',\n",
       " 'Cathleen',\n",
       " 'Cathlene',\n",
       " 'Cathrin',\n",
       " 'Cathrine',\n",
       " 'Cathryn',\n",
       " 'Cathy',\n",
       " 'Cathyleen',\n",
       " 'Cati',\n",
       " 'Catie',\n",
       " 'Catina',\n",
       " 'Catlaina',\n",
       " 'Catlee',\n",
       " 'Catlin',\n",
       " 'Catrina',\n",
       " 'Catriona',\n",
       " 'Caty',\n",
       " 'Cayla',\n",
       " 'Cecelia',\n",
       " 'Cecil',\n",
       " 'Cecile',\n",
       " 'Ceciley',\n",
       " 'Cecilia',\n",
       " 'Cecilla',\n",
       " 'Cecily',\n",
       " 'Ceil',\n",
       " 'Cele',\n",
       " 'Celene',\n",
       " 'Celesta',\n",
       " 'Celeste',\n",
       " 'Celestia',\n",
       " 'Celestina',\n",
       " 'Celestine',\n",
       " 'Celestyn',\n",
       " 'Celestyna',\n",
       " 'Celia',\n",
       " 'Celie',\n",
       " 'Celina',\n",
       " 'Celinda',\n",
       " 'Celine',\n",
       " 'Celinka',\n",
       " 'Celisse',\n",
       " 'Celle',\n",
       " 'Cesya',\n",
       " 'Chad',\n",
       " 'Chanda',\n",
       " 'Chandal',\n",
       " 'Chandra',\n",
       " 'Channa',\n",
       " 'Chantal',\n",
       " 'Chantalle',\n",
       " 'Charil',\n",
       " 'Charin',\n",
       " 'Charis',\n",
       " 'Charissa',\n",
       " 'Charisse',\n",
       " 'Charita',\n",
       " 'Charity',\n",
       " 'Charla',\n",
       " 'Charlean',\n",
       " 'Charleen',\n",
       " 'Charlena',\n",
       " 'Charlene',\n",
       " 'Charline',\n",
       " 'Charlot',\n",
       " 'Charlott',\n",
       " 'Charlotta',\n",
       " 'Charlotte',\n",
       " 'Charmain',\n",
       " 'Charmaine',\n",
       " 'Charmane',\n",
       " 'Charmian',\n",
       " 'Charmine',\n",
       " 'Charmion',\n",
       " 'Charo',\n",
       " 'Charyl',\n",
       " 'Chastity',\n",
       " 'Chelsae',\n",
       " 'Chelsea',\n",
       " 'Chelsey',\n",
       " 'Chelsie',\n",
       " 'Chelsy',\n",
       " 'Cher',\n",
       " 'Chere',\n",
       " 'Cherey',\n",
       " 'Cheri',\n",
       " 'Cherianne',\n",
       " 'Cherice',\n",
       " 'Cherida',\n",
       " 'Cherie',\n",
       " 'Cherilyn',\n",
       " 'Cherilynn',\n",
       " 'Cherin',\n",
       " 'Cherise',\n",
       " 'Cherish',\n",
       " 'Cherlyn',\n",
       " 'Cherri',\n",
       " 'Cherrita',\n",
       " 'Cherry',\n",
       " 'Chery',\n",
       " 'Cherye',\n",
       " 'Cheryl',\n",
       " 'Cheslie',\n",
       " 'Chiarra',\n",
       " 'Chickie',\n",
       " 'Chicky',\n",
       " 'Chiquita',\n",
       " 'Chloe',\n",
       " 'Chloette',\n",
       " 'Chloris',\n",
       " 'Chris',\n",
       " 'Chriss',\n",
       " 'Chrissa',\n",
       " 'Chrissie',\n",
       " 'Chrissy',\n",
       " 'Christa',\n",
       " 'Christabel',\n",
       " 'Christabella',\n",
       " 'Christabelle',\n",
       " 'Christal',\n",
       " 'Christalle',\n",
       " 'Christan',\n",
       " 'Christean',\n",
       " 'Christel',\n",
       " 'Christen',\n",
       " 'Christi',\n",
       " 'Christian',\n",
       " 'Christiana',\n",
       " 'Christiane',\n",
       " 'Christie',\n",
       " 'Christin',\n",
       " 'Christina',\n",
       " 'Christine',\n",
       " 'Christy',\n",
       " 'Christyna',\n",
       " 'Chrysa',\n",
       " 'Chrysler',\n",
       " 'Chrystal',\n",
       " 'Chryste',\n",
       " 'Chrystel',\n",
       " 'Ciara',\n",
       " 'Cicely',\n",
       " 'Cicily',\n",
       " 'Ciel',\n",
       " 'Cilka',\n",
       " 'Cinda',\n",
       " 'Cindee',\n",
       " 'Cindelyn',\n",
       " 'Cinderella',\n",
       " 'Cindi',\n",
       " 'Cindie',\n",
       " 'Cindra',\n",
       " 'Cindy',\n",
       " 'Cinnamon',\n",
       " 'Cissie',\n",
       " 'Cissy',\n",
       " 'Clair',\n",
       " 'Claire',\n",
       " 'Clara',\n",
       " 'Clarabelle',\n",
       " 'Clare',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "names.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ The Tragedie of Hamlet by William Shakespeare 1599 ] Actus Primus . Scoena Prima . Enter Barnardo and Francisco two Centinels . Barnardo . Who ' s there ? Fran . Nay answer me : Stand & vnfold your selfe Bar . Long liue the King Fran . Barnardo ? Bar . He Fran . You come most carefully vpon your houre Bar . ' Tis now strook twelue , get thee to bed Francisco Fran . For this releefe much thankes : ' Tis bitter cold , And I am sicke at heart Barn . Haue you had quiet Guard ? Fran . Not a Mouse stirring Barn . Well , goodnight . If you do meet Horatio and Marcellus , the Riuals of my Watch , bid them make hast . Enter Horatio and Marcellus . Fran . I thinke I heare them . Stand : who ' s there ? Hor . Friends to this ground Mar . And Leige - men to the Dane Fran . Giue you good night Mar . O farwel honest Soldier , who hath relieu ' d you ? Fra . Barnardo ha ' s my place : giue you goodnight . Exit Fran . Mar . Holla Barnardo Bar . Say , what is Horatio there ? Hor . A peece of him Bar . Welcome Horatio , welcome good Marcellus Mar . What , ha ' s this thing appear ' d againe to night Bar . I haue seene nothing Mar . Horatio saies , ' tis but our Fantasie , And will not let beleefe take hold of him Touching this dreaded sight , twice seene of vs , Therefore I haue intreated him along With vs , to watch the minutes of this Night , That if againe this Apparition come , He may approue our eyes , and speake to it Hor . Tush , tush , ' twill not appeare Bar . Sit downe a - while , And let vs once againe assaile your eares , That are so fortified against our Story , What we two Nights haue seene Hor . Well , sit we downe , And let vs heare Barnardo speake of this Barn . Last night of all , When yond same Starre that ' s Westward from the Pole Had made his course t ' illume that part of Heauen Where now it burnes , Marcellus and my selfe , The Bell then beating one Mar . Peace , breake thee of : Enter the Ghost . Looke where it comes againe Barn . In the same figure , like the King that ' s dead Mar . Thou art a Scholler ; speake to it Horatio Barn . Lookes it not like the King ? Marke it Horatio Hora . Most like : It harrowes me with fear & wonder Barn . It would be spoke too Mar . Question it Horatio Hor . What art "
     ]
    }
   ],
   "source": [
    "for word in hamlet[:500]:\n",
    "    print(word, sep=' ', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI = \"\"\"Hi Kate, \n",
    "\n",
    "Thank you for your interest in applying with us. We'd like to schedule you for an interview on tomorrow at 12:00 NN here in our Ortigas office. Our site is located at Unit 708, State Centre II Building, Ortigas Avenue, Mandaluyong City (between POEA and Honda Cars Greenhills). Please don't forget to bring a valid ID and a copy of your resume and look for me when you get to our office. \n",
    "\n",
    "Looking forward to seeing you here. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'Kate',\n",
       " ',',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'your',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'applying',\n",
       " 'with',\n",
       " 'us',\n",
       " '.',\n",
       " 'We',\n",
       " \"'d\",\n",
       " 'like',\n",
       " 'to',\n",
       " 'schedule',\n",
       " 'you',\n",
       " 'for',\n",
       " 'an',\n",
       " 'interview',\n",
       " 'on',\n",
       " 'tomorrow',\n",
       " 'at',\n",
       " '12:00',\n",
       " 'NN',\n",
       " 'here',\n",
       " 'in',\n",
       " 'our',\n",
       " 'Ortigas',\n",
       " 'office',\n",
       " '.',\n",
       " 'Our',\n",
       " 'site',\n",
       " 'is',\n",
       " 'located',\n",
       " 'at',\n",
       " 'Unit',\n",
       " '708',\n",
       " ',',\n",
       " 'State',\n",
       " 'Centre',\n",
       " 'II',\n",
       " 'Building',\n",
       " ',',\n",
       " 'Ortigas',\n",
       " 'Avenue',\n",
       " ',',\n",
       " 'Mandaluyong',\n",
       " 'City',\n",
       " '(',\n",
       " 'between',\n",
       " 'POEA',\n",
       " 'and',\n",
       " 'Honda',\n",
       " 'Cars',\n",
       " 'Greenhills',\n",
       " ')',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'forget',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'a',\n",
       " 'valid',\n",
       " 'ID',\n",
       " 'and',\n",
       " 'a',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'your',\n",
       " 'resume',\n",
       " 'and',\n",
       " 'look',\n",
       " 'for',\n",
       " 'me',\n",
       " 'when',\n",
       " 'you',\n",
       " 'get',\n",
       " 'to',\n",
       " 'our',\n",
       " 'office',\n",
       " '.',\n",
       " 'Looking',\n",
       " 'forward',\n",
       " 'to',\n",
       " 'seeing',\n",
       " 'you',\n",
       " 'here',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_tokens = word_tokenize(AI)\n",
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'.': 15, ',': 12, 'you': 12, 'to': 12, 'for': 9, 'our': 9, 'and': 9, 'your': 6, 'in': 6, 'at': 6, ...})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in AI_tokens:\n",
    "    fdist[word.lower()]+=1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['kate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 15),\n",
       " (',', 12),\n",
       " ('you', 12),\n",
       " ('to', 12),\n",
       " ('for', 9),\n",
       " ('our', 9),\n",
       " ('and', 9),\n",
       " ('your', 6),\n",
       " ('in', 6),\n",
       " ('at', 6)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10 = fdist.most_common(10)\n",
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "AI_blank = blankline_tokenize(AI)\n",
    "len(AI_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Kate,'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI_blank[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'best',\n",
       " 'and',\n",
       " 'most',\n",
       " 'beautiful',\n",
       " 'things',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'can',\n",
       " 'not',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'or',\n",
       " 'even',\n",
       " 'touched',\n",
       " ',',\n",
       " 'they',\n",
       " 'must',\n",
       " 'be',\n",
       " 'felt',\n",
       " 'with',\n",
       " 'the',\n",
       " 'heart',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'The best and most beautiful things in the world cannot be seen or even touched, they must be felt with the heart.'\n",
    "quotes_tokens = nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best'),\n",
       " ('best', 'and'),\n",
       " ('and', 'most'),\n",
       " ('most', 'beautiful'),\n",
       " ('beautiful', 'things'),\n",
       " ('things', 'in'),\n",
       " ('in', 'the'),\n",
       " ('the', 'world'),\n",
       " ('world', 'can'),\n",
       " ('can', 'not'),\n",
       " ('not', 'be'),\n",
       " ('be', 'seen'),\n",
       " ('seen', 'or'),\n",
       " ('or', 'even'),\n",
       " ('even', 'touched'),\n",
       " ('touched', ','),\n",
       " (',', 'they'),\n",
       " ('they', 'must'),\n",
       " ('must', 'be'),\n",
       " ('be', 'felt'),\n",
       " ('felt', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'heart'),\n",
       " ('heart', '.')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best', 'and'),\n",
       " ('best', 'and', 'most'),\n",
       " ('and', 'most', 'beautiful'),\n",
       " ('most', 'beautiful', 'things'),\n",
       " ('beautiful', 'things', 'in'),\n",
       " ('things', 'in', 'the'),\n",
       " ('in', 'the', 'world'),\n",
       " ('the', 'world', 'can'),\n",
       " ('world', 'can', 'not'),\n",
       " ('can', 'not', 'be'),\n",
       " ('not', 'be', 'seen'),\n",
       " ('be', 'seen', 'or'),\n",
       " ('seen', 'or', 'even'),\n",
       " ('or', 'even', 'touched'),\n",
       " ('even', 'touched', ','),\n",
       " ('touched', ',', 'they'),\n",
       " (',', 'they', 'must'),\n",
       " ('they', 'must', 'be'),\n",
       " ('must', 'be', 'felt'),\n",
       " ('be', 'felt', 'with'),\n",
       " ('felt', 'with', 'the'),\n",
       " ('with', 'the', 'heart'),\n",
       " ('the', 'heart', '.')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'best', 'and', 'most', 'beautiful'),\n",
       " ('best', 'and', 'most', 'beautiful', 'things'),\n",
       " ('and', 'most', 'beautiful', 'things', 'in'),\n",
       " ('most', 'beautiful', 'things', 'in', 'the'),\n",
       " ('beautiful', 'things', 'in', 'the', 'world'),\n",
       " ('things', 'in', 'the', 'world', 'can'),\n",
       " ('in', 'the', 'world', 'can', 'not'),\n",
       " ('the', 'world', 'can', 'not', 'be'),\n",
       " ('world', 'can', 'not', 'be', 'seen'),\n",
       " ('can', 'not', 'be', 'seen', 'or'),\n",
       " ('not', 'be', 'seen', 'or', 'even'),\n",
       " ('be', 'seen', 'or', 'even', 'touched'),\n",
       " ('seen', 'or', 'even', 'touched', ','),\n",
       " ('or', 'even', 'touched', ',', 'they'),\n",
       " ('even', 'touched', ',', 'they', 'must'),\n",
       " ('touched', ',', 'they', 'must', 'be'),\n",
       " (',', 'they', 'must', 'be', 'felt'),\n",
       " ('they', 'must', 'be', 'felt', 'with'),\n",
       " ('must', 'be', 'felt', 'with', 'the'),\n",
       " ('be', 'felt', 'with', 'the', 'heart'),\n",
       " ('felt', 'with', 'the', 'heart', '.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens, 5))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem('affection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: give\n",
      "giving: give\n",
      "gave: gave\n",
      "given: given\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = ['give', 'giving', 'gave', 'given']\n",
    "for words in words_to_stem:\n",
    "    print(words + ': ' + pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: giv\n",
      "giving: giv\n",
      "gave: gav\n",
      "given: giv\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "for words in words_to_stem:\n",
    "    print(words + ': ' + lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "sbst = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: give\n",
      "giving: give\n",
      "gave: gave\n",
      "given: given\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words + ': ' + sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lem.lemmatize('corpora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give: give\n",
      "giving: giving\n",
      "gave: gave\n",
      "given: given\n"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words + ': ' + word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 15),\n",
       " (',', 12),\n",
       " ('you', 12),\n",
       " ('to', 12),\n",
       " ('for', 9),\n",
       " ('our', 9),\n",
       " ('and', 9),\n",
       " ('your', 6),\n",
       " ('in', 6),\n",
       " ('at', 6)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation = re.compile(\"r'[-,?!,:;()|0-9]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_punctuation = []\n",
    "for words in AI_tokens:\n",
    "    word = punctuation.sub('', words)\n",
    "    if len(word)>0:\n",
    "        post_punctuation.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " 'Kate',\n",
       " ',',\n",
       " 'Thank',\n",
       " 'you',\n",
       " 'for',\n",
       " 'your',\n",
       " 'interest',\n",
       " 'in',\n",
       " 'applying',\n",
       " 'with',\n",
       " 'us',\n",
       " '.',\n",
       " 'We',\n",
       " \"'d\",\n",
       " 'like',\n",
       " 'to',\n",
       " 'schedule',\n",
       " 'you',\n",
       " 'for',\n",
       " 'an',\n",
       " 'interview',\n",
       " 'on',\n",
       " 'tomorrow',\n",
       " 'at',\n",
       " '12:00',\n",
       " 'NN',\n",
       " 'here',\n",
       " 'in',\n",
       " 'our',\n",
       " 'Ortigas',\n",
       " 'office',\n",
       " '.',\n",
       " 'Our',\n",
       " 'site',\n",
       " 'is',\n",
       " 'located',\n",
       " 'at',\n",
       " 'Unit',\n",
       " '708',\n",
       " ',',\n",
       " 'State',\n",
       " 'Centre',\n",
       " 'II',\n",
       " 'Building',\n",
       " ',',\n",
       " 'Ortigas',\n",
       " 'Avenue',\n",
       " ',',\n",
       " 'Mandaluyong',\n",
       " 'City',\n",
       " '(',\n",
       " 'between',\n",
       " 'POEA',\n",
       " 'and',\n",
       " 'Honda',\n",
       " 'Cars',\n",
       " 'Greenhills',\n",
       " ')',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " \"n't\",\n",
       " 'forget',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'a',\n",
       " 'valid',\n",
       " 'ID',\n",
       " 'and',\n",
       " 'a',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'your',\n",
       " 'resume',\n",
       " 'and',\n",
       " 'look',\n",
       " 'for',\n",
       " 'me',\n",
       " 'when',\n",
       " 'you',\n",
       " 'get',\n",
       " 'to',\n",
       " 'our',\n",
       " 'office',\n",
       " '.',\n",
       " 'Looking',\n",
       " 'forward',\n",
       " 'to',\n",
       " 'seeing',\n",
       " 'you',\n",
       " 'here',\n",
       " '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Timothy is a natural when it comes to drawing'\n",
    "sent_tokens = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Timothy', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_sent = 'The US President stays in the WHITE HOUSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "NE_tokens = word_tokenize(NE_sent)\n",
    "NE_tags = nltk.pos_tag(NE_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  T/NNP\n",
      "  h/NN\n",
      "  e/NN\n",
      "   /NNP\n",
      "  U/NNP\n",
      "  S/NNP\n",
      "   /NNP\n",
      "  P/NNP\n",
      "  r/NN\n",
      "  e/NN\n",
      "  s/NN\n",
      "  i/NN\n",
      "  d/VBP\n",
      "  e/NN\n",
      "  n/JJ\n",
      "  t/NN\n",
      "   /NNP\n",
      "  s/VBZ\n",
      "  t/VB\n",
      "  a/DT\n",
      "  y/NN\n",
      "  s/NN\n",
      "   /NN\n",
      "  i/NN\n",
      "  n/VBP\n",
      "   /JJ\n",
      "  t/NN\n",
      "  h/NN\n",
      "  e/NN\n",
      "   /NNP\n",
      "  W/NNP\n",
      "  H/NNP\n",
      "  I/PRP\n",
      "  T/NNP\n",
      "  E/NNP\n",
      "   /NNP\n",
      "  H/NNP\n",
      "  O/NNP\n",
      "  U/NNP\n",
      "  S/NNP\n",
      "  E/NNP)\n"
     ]
    }
   ],
   "source": [
    "NE_ner = ne_chunk(NE_tags)\n",
    "print(NE_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
